* Liste des articles et cours lus pendant le stage et résumé de ce que j'y ai appris

** 1 - Cours d'introduction à la cryptographie de L3 - Adeline Roux Langlois (voir documents persos) 
- notion de sécurité CPA (l'attaquant, en regardant un chiffré, ne peut pas recuperer d'information non négligeable sur le message d'origine)
- notion de sécurité CCA (l'attaquant, en pouvant décoder des messages autre que le challenge, ne peut pas savoir d'informations non négligeable sur le message d'origine)
- gaussienne discrète sur Z et le fait que les valeurs sont presque toutes de norme faible (pour une gaussienne de paramètre s, autour de s*sqrt(n) )
- découverte du problème LWE calculatoire et décisionnel (on a m produits scalaires avec un vecteur secret s de Z^{n}, les produits sont brouillés par une gaussienne discrete)
- découverte d'un chiffrement reposant sur LWE (chiffrement de Regev) ( en recevant (A,b) en clé publique, on échantillonne r avec des valeurs 0 ou 1 puis on renvoie (r^{T}A,r^{T}b+floor(q/2)*M) )
- énoncé du Leftover Hash Lemma (si une matrice et un vecteur sont choisis de manière uniforme, leur produit est a distance négligeable de la distribution uniforme)
- notion de résistance aux collisions (un adversaire ne peut pas renvoyer une collision pour la fonction de hash avec une proba non négligeable )
- découverte du problème SIS ( pour une matrice a coefficients entier, trouver un vecteur petit de \Lambda_{\bot} (A) )
- découverte d'une fonction de hachage reposant sur SIS ( x est le message a coefficients dans 0 et 1 (donc court), la fonction renvoie Ax mod q )
- découverte des schémas de signature ( schémas qui permettent de prouver l'identité d'une personne, la clé secrète encrypte et celle publique décrypte)

** 2 - Cours d'introduction à la cryptographie sur les réseaux euclidiens - Adeline Roux Langlois (voir documents persos)
- notions de base sur un réseau euclidien ( bases, premier minimum, dernier minimum, théorèmes de minkowski )
- introduction aux problèmes SVP, CVP et à leur variantes approchées ( étant donné une base d'un réseau, trouver le vecteur non nul le plus petit du réseau ou le plus proche d'un point donné)
- search SVP et decisional SVP ( Avec search SVP, decisional SVP est résolu très facilement. Avec decisional SVP, on fait une recherche dichotomique entre ||B|| et 0 pour trouver la distance entre le point et le réseau, puis on utilise decisional SVP pour savoir dans quel sous réseau le vecteur se trouve. Une fois qu'on a un sous réseau exponentiellement plus dilaté que celui de base, on peut appliquer un algorithme poly qui trouve le vecteur le plus proche avec une facteur d'approximation exponentiel)
- il existe une réduction de GapSVP à GapCVP (on appelle GapCVP sur les réseau B_i où ou a multiplié par deux le vecteur b_{i} et pour cible b_{i}. Si on a une instance NON, les instances de GapCVP aussi. Si on a une instance OUI, on a un vecteur v tq ||v+b_{i}-b_{i}||<=r et v+b_{i} est dans B_{i} donc on a une instance OUI de GapCVP )
- Complexité de GapSVP (GapCVP_{\gamma} est NP dur pour \gamma constant, NP \cap coNP pour \gamma = sqrt(n), et difficile pour \gamma = poly(n). Pour \gamma = 2^{O(n)}, il y a un algo poly)
- introduction au réseau dual ( l'ens des point formant un pdt scalaire entier avec les pt du réseau )
- inégalité plus générale sur les gaussiennes (pour une gaussienne de paramètre s, proba que le vecteur soit >= s*t est inférieur à exp(-\pi*t^2) )
- introduction du smoothing parameter (qui permet d'avoir certaines ptés de la gaussienne discrète sur la gaussienne continue)
- pour un paramètre suffisamment grand, la gaussienne modulo un sous réseau est indistinguable de la proba uniforme modulo le sous réseau.
- On peut échantillonner la gaussienne discrète sur un réseau donné ( pourvu que s soit assez grand ) (voir papier n°3)
- découverte du problème SIVP (étant donné un réseau trouver n vecteurs cours indépendants)
- il existe une réduction de SIVP à SIS ( on échantillonne n vecteurs de la gaussienne que l'on transforme en problème SIS; puisque les vecteurs échantillonnés sont courts, on obtient un vecteur qui est toujours sur le réseau mais plus petit, on répète ça pour obtenir un ensemble de vecteur linéairement indépendants puis on réitère la procédure jusqu'à avoir un des vecteurs suffisamment petits)
- search LWE et decisional LWE sont équivalents ( pour résoudre search en ayant decisional, on devine chaque coordonnée une à une; si on tombe sur la bonne, on a une distribution de LWE, sinon on a une distribution uniforme )
- il existe une réduction quantique de GapSVP à LWE ( voir présentation n°4 )
- découverte du chiffrement dual Regev (au lieu que la clé privée est r (coef dans 0 et 1) et la clé publique est y =r^{T}A  mod q (donc la clé secrète n'est plus s) 
- définition d'une trappe pour les problèmes de réseau (base courte de \Lambda_{q}^{\bot}(A), avec laquelle on peut résoudre beaucoup de problèmes compliqués facilement et échantillonner la gaussienne avec un paramètre petit ) (voir papier n°3)
- présentation d'un algorithme permettant de générer une trappe en même temps qu'une matrice, et de faire en sorte que la matrice soit proche de l'uniforme 
- découverte du schéma de signature GPV, dont la sécurité repose sur SIS ( utiliser une trappe pour générer un vecteur avec une certaine propriété (compliqué à faire sans la trappe), pour vérifier, on a juste à vérifier si le vecteur respecte la bonne pté )
- on peut construire des réseaux avec des coefs dans un anneau de polynôme (typiquement, Z[X]/(X^{n}+1) ) pour avoir des multiplication un peu plus efficace. Malheureusement, certains problèmes standards sur les réseaux n'ont pas été prouvés comme durs ( voir présentation n°6)
- découverte du problème ring-SIS_{q,m,\beta} (notons R= Z[X]/(X^{n}+1). Etant donné a=(a_{1},...,a_{m}) m polynômes de R_{q} tirés uniforméments, trouver x=(x_{1},...,x_{m}) polynômes de R tq ||x||=max(||x_{i}||)<=\beta et \Sigma a_{i}.x_{i} = 0 )

** 3 - How to Use a Short Basis: Trapdoors for Hard Lattices and New Cryptographic Constructions - Gentry, Peikert et Vaikuntanathan ( https://eprint.iacr.org/2007/432.pdf )
L'article présente un moyen efficace échantillonner la gaussienne discrète sur n'importe quel réseau, et utilise le fait qu'on puisse générer une matrice uniforme et une trappe (voir cours n°2) pour construire plusieurs primitives cryptographiques dont un IBE et un système de chiffrement reposant sur LWE et pouvant posséder des clés "messy".
- découverte de la notion d'IBE ( un système où une clé publique permet d'encrypter un message pour tout le monde, et une clé secrète  "maitresse" permet de générer une clé secrète pour chaque utilisateur )
- l'article explique comment échantillonner la gaussienne discrète sur Z ( en sachant qu'avec une proba de type 1-negl, l’échantillon est dans [c-s*\omega(sqrt(log(n))),c+\omega(sqrt(log(n)))], on peut appliquer une méthode de rejet sur cet intervalle pour obtenir un échantillon gaussien)
- à l'aide de cette gaussienne, on peut échantillonner celle sur un réseau quelconque ( il s'agit d'une méthode utilisant les vecteurs de Gramm-Schmitt de la base )
- formules entre \Lambda et \Lambda_{\bot} (vues en TD du cours n° 2)
- on retrouve dans l'article la fonction de hachage présentée dans le cours n°1
- on retrouve le chiffrement dual Regev
- présentation d'un IBE basé sur le chiffrement dual Regev utilisant à la fois les trappes et échantillonnage sur une gaussienne discrète ( la clé publique est A, ca clé privée est une trappe, pour générer une clé privée pour une identité id, on prend un vecteur u=H(id) et on trouve un vecteur e tq Ae = u mod q et tel que e est court, ce qui ets possible car on peut générer la gaussienne de \Lambda_{\bot} grâce à la trappe)
- présentation d'un système de chiffrement dont la sécurité repose sur LWE ( clé secrète : s uniforme, clé publique : p = A^{T}s+x ou x est gaussien, pour encrypter, on choisi e gaussien de Z^{m} et on retourne (Ae,p^{T}e+M*floor(q/2)) )
- définition de clés "messy" (clés pour lesquelles les chiffrés sont indistinguables de vecteurs choisis uniformément )
- présentation d'un algorithme permettant d’identifier si une clé est "messy" avec une probabilité exponentiellement faible pour l'algorithme basé sur LWE
- La réduction de SIVP à SIS du cours n°2 est présentée de manière plus détaillée en fin d'article ( comme une bonne partie des algorithmes présentés, cette réduction utilise l'algorithme échantillonnage de la gaussienne sur les réseaux)

** 4 - Proving Hardness of LWE - Regev ( présentation d'article en vidéo : https://www.youtube.com/watch?v=Z4DM3qhH6pA et https://people.csail.mit.edu/vinodv/6892-Fall2013/regev.pdf )
J'ai regardé la vidéo et j'ai lu l'intro de l'article. Dans sa présentation, Regev détaille un algorithme ayant accès à un oracle de LWE pour trouver un vecteur cours d'un réseau (et donc cela permet de résoudre des problèmes classiques de réseaux, par exemple SVP ).
- découverte du problème BDD, qui selon Regev n'a de l'utilité qu'en info quantique ( étant un vecteur "proche" d'un point du réseau, trouver le point du réseau le plus proche )
- l'algo présenté repose sur la proposition suivante : avec un échantillon de taille poly(n) de vecteurs échantillonnés sur une gaussienne de paramètre r, je peux échantillonner un autre échantillon de même taille de paramètre r/2 à l'aide de LWE. Pour réaliser ca, Regev présente 2 lemmes.
- lemme 2: étant donné un oracle qui résout BDD_{d}, je peux sampler la gaussienne de paramètre sqrt(n)/d ( vu que c'est quantique, je comprend pas très bien, mais l'idée est de calculer la fonction f_{d/srqt(n)} (celle qui fait des gaussiennes sur les points du dual) de manière quantique, en enlevant un état qui nous gène en "enlevant" les points du dual de l’état avec BDD, et ensuite on fait une transformée de fourrier quantique pour trouver la distribution gaussienne de paramètre sqrt(n)/d)
- lemme 1: étant donné un oracle qui résout LWE et des échantillons gaussiens du réseau de paramètre r, je peux résoudre BDD_{p/r} (l'idée est que à l'aide de f_{p/r}, on peut faire une descente de gradient et trouver le point le plus proche en remontant la colline formée par la gaussienne. Pour p=1, il s'agit juste d'un calcul d’espérance et f_{1/r} est trouvable facilement. Ça se complique pour p>=2; on divise le réseau en p^{n} sous réseaux et à partir des échantillons de la gaussiennes, on peut avoir des échantillons sur la proba marginale ou l'on choisi d'abord le sous réseau puis on fait une gaussienne dessus. Ensuite, selon dans quel sous réseau les échantillons sont pris, les pics de f peuvent êtres inversés. Pour trouver dans quel sens renverser la gaussienne, on peut utiliser <s,t> mod p pour chaque échantillon ou t est le vecteur qui correspond au sous réseau d'on proviens l’échantillon et s dépend de x uniquement. Avec des erreurs, cela correspond à <x,w> mod p où x est le point auquel on essaye d'approcher la fonction et w est un échantillon. On peut donc utiliser LWE pour trouver s et redresser les gaussiennes. )
J'ai toujours une certaine interrogation à propos du lemme 2. Pourquoi a t on besoin de connaître <s,t> mod p pour corriger la valeur d'un échantillon? Je suis sur que c'est complètement faux, mais je ne comprend pas pourquoi on ne pourrait pas juste prendre l’espérance des valeurs absolues, au lieu de faire l’espérance simple. Peut être que le fait de n'avoir qu'un échantillon par sous réseaux fait que ce n'est pas possible?...

** 5 - The Mathematics of Latices - Vaikuntanathan ( https://www.youtube.com/watch?v=LlPXfy6bKIY et https://www.youtube.com/watch?v=SZkTJMorxnM ) 
- rappel de quelques bases et généralités sur les réseaux et de certains problèmes sur les réseaux
- résumé des différentes complexités pour le problème GapSVP selon \gamma (présent dans le cours n°2 )
- on y retrouve la fonction de hash du cours n°1
- on y retrouve également la réduction de SIVP à SIS du cours n°2
- présentation d'une fonction de hash reposant sur LWE ( en prenant (s,e) avec e petit, g_{A}(s,e)=As+e ) et de la fonction de hash reposant sur SIS (du cours n°1)
- le chiffrement de Regev du cours n°1 est présenté
- présentation de l'algorithme de Babai qui permet de résoudre CVP si on a une bonne base pour un réseau (étant donné un vecteur y et la base du réseau B, on renvoie v = B.int(B^{-1}y). On a alors v sur le réseau et ||v-y|| <= 1/2*||B|| où ||B|| = \Sigma b_{i} )
- présentation d'algorithmes pour utiliser les trapes pour inverser les fonctions de hash présentées à l'aide de l'algorithme de Babai
- l'algorithme de génération de matrice avec la trappe est présenté (algo présent dans le cours n°2 )
Globalement, cette présentation ne m'a pas appris autant de chose que les documents précédents, mais elle m'a permit de mieux comprendre certaines notions (notamment la réduction de SIVP à SIS, qui était bien expliquée et illustrée). J'ai également pu découvrir l'algorithme de Babai de manière explicite. 

** 6 - Présentation sur Ring-LWE - Lyubashevsky ( https://www.youtube.com/watch?v=okJwRM0Yu7E )
Comme son nom l'indique, cette présentation m'a servi d'introduction aux réseaux reposants sur d'autres anneaux que les Z^{n}.
La présentation introduit les réseaux dans d'autres espaces que Z^{n}, par exemple les réseaux cycliques ( dans Z[X]/(X^{n}-1 ) ) et idéaux
- définition d'un réseau f-idéal ( réseau dans Z[X]/f(X) où f est de coefficient dominant 1, irréductible, et il existe poly(n) tq pour tout polynômes g et h, on doit avoir ||gh mod f|| <= poly(n)*||f||*||g|| )
- les f tq f=X^{n}+1 où n est une puissance de 2 sont les plus utilisés
- on ne sait pas grand chose de la difficulté des problèmes de réseaux classiques adaptés aux réseaux idéaux, sauf que GapSVP est facile à résoudre à partir de \gamma = sqrt(n)
- définition de ring-LWE, équivalent de LWE dans les réseaux idéaux (on prend a_{1}, ..., a_{n} dans, s dans l'anneau de manière uniforme, et e_{1}, ..., e_{n} gaussiens dans l'anneau, et le pb porte sur les (a_{i},a_{i}*s+e_{i}) )
- on peut montrer (apparemment de manière similaire à Regev à le présentation 4, mais je sais pas comment) que search ring-LWE est dur (ie on peut résoudre des problèmes sur les réseaux avec un oracle résolvant ce problème)
- il existe une réduction de search ring-LWE à decision ring-LWE ( la démo est similaire à la même réduction dans les réseaux classiques; on devine les coefs un à un )

** 7 - Lattice-based Cryptography - Micciancio et Regev ( https://cseweb.ucsd.edu/~daniele/papers/PostQuantum.pdf )
Un peu moins théorique que le reste des articles et un peu plus orienté vers l'implémentation, cet article liste un bon nombre de schémas cryptographiques reposant sur les réseaux euclidiens et fait la distinction entre ceux n'ayant pas de preuve de sécurité mais étant efficaces, et ceux prouvés comme sûrs mais étant moins efficaces voire inutilisables en pratique.
- l'article présente la fonction de hash du cours n°1. Elle a été inventée par Ajtai.
- Comme cette fonction n'est pas très efficace à calculer, plusieurs propositions visent à améliorer la complexité asymptotique ( première idée : matrices circulantes s'apparentant à de la multiplication sur Z[X]/(X^{n}-1) mais moins de preuves de sécurité. par contre, les matrices s'apparentant à de la multiplication sur Z[X]/(X^{n}+1) ont une preuve de sécurité reposant sur SVP sur les réseaux idéaux, et on peut utiliser la FFT pour optimiser le calcul de la fonction et la clé publique est moins lourde)
- présentation du schéma de chiffrement NTRU, non prouvé sûr mais jamais cassé ( l'algorithme utilise les réseaux idéaux, est un peu plus complexe à comprendre que d'habitude et est assez particulier, mais les clé privées et publiques sont assez légères (seulement un ou deux vecteurs de Z_{q}^{n} ) et les algorithmes encryptions et de décryptions sont plutôt efficaces )
- Le papier détaille un des schémas de chiffrement les plus efficaces ayant une preuve de sécurité, il est basé sur LWE ( clé publique: matrice S choisie au hasard, clé publique: (A,P=AS+E) ou A est prise au hasard et E matrice de coef gaussien. Pour encrypter, (u=A^{T}a,c=P^{T}a+f(v)). Pour décrypter, f^{-1}(c-S^{T}u). f(x)=q/t*int(x) )
- Cet algorithme requiert beaucoup de paramètres, mais une fois les bons paramètres choisis, l'algorithme peut être prouvé comme sécurisé et peut avoir des clés "messy" ( comme dans l'article n°3 )
- référence à l'IBE présent dans l'article n°3

** 8 - Robustness of the Learning with Errors Assumption - Goldwasser, Kalai, Peikert et Vaikuntanathan ( https://web.eecs.umich.edu/~cpeikert/pubs/robustlwe.pdf )
J'ai lu cet article jusqu'à la preuve du théorème important. Cet article traite de d'une preuve de robustesse de LWE dans un cas particulier; jusqu'ici, on avait supposé que le secret s du problème était tiré selon une distribution uniforme. Mais que se passe-t-il si la clé n'est pas tirée uniformément (cela peut être le cas en pratique)? L'article montre justement qu'avec une entropie suffisante, on peut conserver une preuve de sécurité.
- explication du paradigme de "graceful degradation of security" ( D'habitude, pour contrer le fait que la clé peut fuiter, le concepteur de la primitive estime la fuite max et construit ensuite la primitive. Ici, on conçoit l'algorithme et on constate que la preuve de sécurité est plus faible si la clé fuite; on a donc pas de perte d'efficacité en fonction de la fuite de la clé, contrairement à avant)
- lemme 3 : si y est pris d'une gaussienne de paramètre \beta.q, alors |y|<=\beta.q avec proba accablante. De plus, la distance stat entre la gaussienne_{\beta q} et  la gaussienne_{\beta.q} + y est au plus |y|/(\beta.q) (appelons le 2e lemme de décalage)
- présentation et preuve du théorème principal à traiter : pour D distribution d'entropie min k ou plus, n et q entiers, \alpha et \beta > 0 tel que \alpha/\beta = negl(n), alors pour l<=(k-\omega(log(n)))/log(q), il y a une réduction de LWE_{l,q,\alpha} à LWE_{n,q,\beta}(D)
- je trouve la preuve un peu perturbante parce que j'ai l'impression que la réduction est dans le sens contraire des réductions habituelles (au lieu de prouver que si pb 1 est facile, alors pb 2 est facile, on prouve que su pb est dur, pb 1 est dur )
- la preuve repose sur la décomposition de A' en BC+Z où Z a des coefs tirés parmi une gaussienne (ce qui rend A' indistinguable de l'uniforme)
- ensuite, il suffit de prouver que (B,C,Z,BCs+Zs+x) et (B,C,Z,u) sont indistinguables. Pour cela, on utilise le lemme 3: les coefs de Z sont petits et s est a coef dans 0 et 1, donc la distance entre Zs+x et x est statistiquement petite. 
- Il suffit donc de prouver que (B,C,Z,BCs+x) et (B,C,Z,u) sont indistinguables donc il suffit de prouver que (B,C,BCs+x) et (B,C,u) sont indistinguables car on peut échantillonner Z efficacement
- Par le leftover hash lemma et des calculs, on obtient que (C,Cs) et (C,u) sont indistinguables, car s a une entropie suffisante. Donc pour un décideur PPT, (B,BCs+x) est indistinguable d'une instance de LWE_{l,q,\alpha} pour un secret Cs. Par le fait qu'on a supposé LWE_{l,q,\alpha} dur, on a bien que (B,BCs+x) et (B,u) indistinguables donc (B,C,BCs+x) et (B,C,u) indistinguables.

** 9 - Lattice-based (Partially) Blind Signature without Restart - Bouaziz-Ermann, Canard, Eberhart, Kaim, Roux-Langlois et Traoré ( https://eprint.iacr.org/2020/260.pdf )
Cet article propose une signature aveugle basée sur SIS plus efficace que celles proposées dans des papier précédents, notamment avec son absence de redémarrages complets de protocoles. Plusieurs définitions pour formaliser la sécurité d'un chiffrement aveugle y sont présenté et celle de "blindness" est celle que je dois améliorer.
- définition des signatures aveugles et partiellement aveugles
- la totalité des signatures aveugles basées sur des réseaux nécessitaient des potentiels redémarrages et ces redémarrages complexifiaient la preuve de sécurité. Cet article propose un protocole de signatures aveugles sans redémarrages complets, ce qui donne un schéma plus efficace et dont la sécurité est plus simple à prouver
- introduction du problème k-SIS ( étant donné k vecteurs solutions du problème SIS avec la même matrice A linéairement indépendant, en trouver un k+1e ) ce problème a été prouvé sur pour k = O(n)
- avec le théorème 1, on peut utiliser des méthode de type rejet pour simuler une gaussienne avec une autres gaussienne décalé, et n'avoir aucune info sur le décalage
- rappel du lemme de décalage
- définitions des expériences permettant de définir une signature sure ( "blindness experiment" ; le signataire ne peut pas savoir quel message il a signé, et expérience de "one-more unforgeability" ; l'utilisateur, après l requêtes de signatures, ne peut pas en produire une autre de lui-même sans aide du signataire )
- présentation du "forking lemma" ( si un algo probabiliste a une proba non négligeable de produire une sortie avec une certaine propriété, alors avec une proba non négligeable, en changeant les entrées et en gardant les même choix probabilistes, la deuxième entrée aura elle aussi la même propriété ) ( la formulation du lemme est un peu technique, et je ne suis pas sur encore de comprendre l'utilité de toutes les notations introduites)
- le forking lemme permet de "manipuler" un attaquant qui aurait réussi a créé une signature de lui même pour en produire une autre, ce qui permettra de résoudre des problème compliqués ( comme SIS par exemple )
- présentation du schéma de signature aveugle principal
- preuve de la correction du schéma ( prouver que ||z|| <= D est trivial par construction et IT. Ensuite, pour prouver que H(h_{a}(z)-p*e,M)=e, il s'agit de calculs réinjectés les uns dans les autres selon les différentes étapes utilisés pour calculer les différents vecteurs utilisés )
- preuve du "blindness" du schéma ( on prouve que les éléments une fois aveuglés ont des distributions qui sont indistinguables de distributions qui ne dépendent pas d'élements "désaveuglés", grâce a un lemme introductif et au théorème 1 )

** 10 - Hardness of LWE on General Entropic Distributions - Brakerski et Döttling ( https://www.youtube.com/watch?v=A3nJo3MRKjA et https://eprint.iacr.org/2020/119.pdf )
Ce papier vient améliorer la réduction de l'article n°8, notamment le rapport entre l’écart-type des deux problèmes ( ce qui permet donc d'avoir une réduction plus "forte" ). Pour réaliser cette preuve, les auteurs décompose l'erreur gaussienne en une combinaison linéaire e_{1}F+e_{2}. 
- Dans l'article, on trouve le résultat suivant sur des gaussiennes CONTINUES : Si on prend F une matrice a coefficients entiers, \sigma > \sigma_{1}.|||F|||. Alors pour e vecteur de R^{m} est distribué selon une gaussienne d’écart-type \sigma, elle est de même loi que e_{1}F+e_{2} où F est fixé arbitrairement dans Z^{n.m}, e_{1} suit une distribution gaussienne d’écart-type \sigma_{1} dans R^{n} et e_{2} suit une distribution gaussienne d’écart-type sqrt(\Sigma) dans R^{m} où \Sigma=\sigma^{2}I-\sigma_{1}^{2}F^{T}F .
- 

